# Take a look
1. [Lbis](https://github.com/ibis-project)
2. JVM
3. Julia
4. http://wesmckinney.com/blog/announcing-ursalabs/
5. Pandas
6. Why Arrow
   + [Data Science Without Borders at JupyterCon](https://www.youtube.com/watch?v=wdmf1msbtVs)
   + [Memory Interoperability for Analytics and Machine Learning at Stanfordâ€™s ScaledML](https://www.slideshare.net/wesm/memory-interoperability-in-analytics-and-machine-learning)
   + [Raising the Tides: Open Source Analytics for Data Science at the Newsweek AI and Data Science Conference](https://www.slideshare.net/wesm/raising-the-tides-open-source-analytics-for-data-science)
7. LLVM
8. Understand comprehensive interoperability with existing data representations (e.g. data frames in R, pandas / NumPy in Python
9. dplyr
10. Feather file format
11. [Numfocus](https://numfocus.org/sponsored-projects)
12. https://twosigmaventures.com/
13. Experience building performance and latency-sensitive, data-driven analytical applications.
14. Knowledge of standard data structures and algorithms for data processing, their implementation details, and performance tradeoffs (hash tables, vectors, binary trees, sorting algorithms, etc.).
15. Knowledge of binary data formats, serialization schemes, compression, and other IO performance considerations.
16. Familiar with a variety of database technology.
17. C/C++ experience
18. Extra points if you have programmed in an APL dialect (J or K/Q/Kona) or solved 100 or more problems on Project Euler
19. unit testing and continuous integration
20. Experience with building distributed data systems and analytics tools such as Spark, Crunch, or Pig a plus
21. Maybe you loved the Google Dremel white paper
22. code generation (e.g. LLVM) or compiler technology
23. building applications EC2 or other cloud computing services

# Parallelism

1. multithreaded
2. synchronization
3. concurrency
4. lock/ distributed-lock
5. time/ clock